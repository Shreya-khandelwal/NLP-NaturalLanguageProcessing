{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Doc object and pass unicode string\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla 96 PROPN nsubj\n",
      "is 87 AUX aux\n",
      "looking 100 VERB ROOT\n",
      "at 85 ADP prep\n",
      "buying 100 VERB pcomp\n",
      "U.S. 96 PROPN compound\n",
      "startup 92 NOUN dobj\n",
      "for 85 ADP prep\n",
      "$ 99 SYM quantmod\n",
      "6 93 NUM compound\n",
      "million 93 NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# Print each token seperately\n",
    "for token in doc:\n",
    "    # Print text, part of speech, syntactic dependency\n",
    "    print(token.text, token.pos, token.pos_, token.dep_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x17ce19031c0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x17ce1902ce0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x17ce17dfbc0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x17ce1945800>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x17ce1788280>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x17ce17dfa70>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline object\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get basic names\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "n't PART neg\n",
      "     SPACE dep\n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startuos ADJ pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "doc_2 = nlp(u\"Tesla isn't     looking into startuos anymore.\")\n",
    "\n",
    "for token in doc_2:\n",
    "    print(token.text,token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using index to grab tokens\n",
    "doc_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part of speech\n",
    "doc[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntactic dependency\n",
    "doc_2[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the seocnd sentence.\n",
      "This is the third sentence\n"
     ]
    }
   ],
   "source": [
    "# Print sentences\n",
    "doc_3 = nlp(u\"This is the first sentence. This is the seocnd sentence. This is the third sentence\")\n",
    "\n",
    "for sentence in doc_3.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is this start of the sentence\n",
    "doc_3[6].is_sent_start\n",
    "doc_3[4].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
